{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AT2071/Samples/blob/main/Guided_Generation_Kopal_Garg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: [Kopal Garg](https://www.linkedin.com/in/gargkopal/)\n",
        "\n",
        "Date: June 4, 2024"
      ],
      "metadata": {
        "id": "NcENp5FWEDrN"
      },
      "id": "NcENp5FWEDrN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "5tLGW0o4C_8H"
      },
      "id": "5tLGW0o4C_8H"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install google-cloud-aiplatform\n",
        "!pip install google-auth\n",
        "!pip install google-auth-oauthlib\n",
        "!pip install google-auth-httplib2"
      ],
      "metadata": {
        "id": "5M2-FXSVEZo2",
        "outputId": "2432a339-1216-4a0e-90f0-da426a6288e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5M2-FXSVEZo2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.52.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.7.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.6.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (2.27.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.31.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Authenticate"
      ],
      "metadata": {
        "id": "dQgdUR6SEe1q"
      },
      "id": "dQgdUR6SEe1q"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "5WVzCsCnEeOd"
      },
      "id": "5WVzCsCnEeOd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n"
      ],
      "metadata": {
        "id": "NeWG9lwxC_UW"
      },
      "id": "NeWG9lwxC_UW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f196859e-7ac4-420b-a5b9-83bd904983e0",
      "metadata": {
        "id": "f196859e-7ac4-420b-a5b9-83bd904983e0"
      },
      "source": [
        "# Guided Generation with Regular Expressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e051666-e0c2-4898-8408-9faecd649402",
      "metadata": {
        "tags": [],
        "id": "0e051666-e0c2-4898-8408-9faecd649402",
        "outputId": "7f925261-887b-4afb-de2b-6f9331fcf1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7a5acc138d60>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7a5abde5c5e0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7a5abde5c5e0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ServiceUnavailable",
          "evalue": "503 Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7a5abde5c5e0>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mprefetch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_prefetch_first_result_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             return _StreamingResponseIterator(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefetch_first_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefetch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefetch_first_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stored_first_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7a5abde5c5e0>)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-06-11T20:45:23.674768141+00:00\", grpc_status:14, grpc_message:\"Getting metadata from plugin failed with error: (\\\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\\\nb\\'\\'\\\", <google.auth.transport.requests._Response object at 0x7a5abde5c5e0>)\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b1650193c339>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m }\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mgenerated_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b1650193c339>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_generate_content_streaming\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0mtool_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 572\u001b[0;31m         response_stream = self._prediction_client.stream_generate_content(\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mstream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   2229\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m             )\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServiceUnavailable\u001b[0m: 503 Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7a5abde5c5e0>)"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import re\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "\n",
        "number_pattern = re.compile(r\"^\\d{6}$\")\n",
        "def validate_number(number_str):\n",
        "    if number_pattern.match(number_str):\n",
        "        return True\n",
        "    else:\n",
        "        print(number_str)\n",
        "        print(\"Invalid 6-digit format. Re-prompting...\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def generate():\n",
        "    vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.0-pro-vision-001\",\n",
        "    )\n",
        "    while True:\n",
        "        responses = model.generate_content(\n",
        "            [text1],\n",
        "            generation_config=generation_config,\n",
        "            stream=True,\n",
        "        )\n",
        "\n",
        "        number = \"\"\n",
        "        for response in responses:\n",
        "            number += response.text.strip()\n",
        "\n",
        "        if validate_number(number):\n",
        "            return number\n",
        "\n",
        "text1 = \"\"\"Generate a valid 6-digit number, ensuring it contains exactly 6 digits with no spaces or other characters. It should be in the format XXXXXX.\"\"\"\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 2048,\n",
        "    \"temperature\": 0.4,\n",
        "    \"top_p\": 0.4,\n",
        "    \"top_k\": 32,\n",
        "}\n",
        "\n",
        "generated_number = generate()\n",
        "print(generated_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab54f6dc-00d9-470b-a17d-f989a605b443",
      "metadata": {
        "id": "ab54f6dc-00d9-470b-a17d-f989a605b443"
      },
      "source": [
        "# Guided Generation with JSON Schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f147a4-08ac-4fd3-a9fd-5cabb3234404",
      "metadata": {
        "tags": [],
        "id": "37f147a4-08ac-4fd3-a9fd-5cabb3234404",
        "outputId": "97f1688a-72f9-4336-a6bf-b540e7fe0d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\": \"John Smith\",\n",
            "  \"age\": 32,\n",
            "  \"email\": \"john.smith@example.com\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
        "\n",
        "schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\", \"minimum\": 0},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"age\", \"email\"]\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "Generate a JSON object representing a user profile. The JSON object should have the following structure:\n",
        "{\n",
        "    \"name\": \"a random first and last name\",\n",
        "    \"age\": an age between 20 and 40,\n",
        "    \"email\": \"a unique email address\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def validate_json(instance, schema):\n",
        "    \"\"\" Validate if the generated JSON matches the schema \"\"\"\n",
        "    try:\n",
        "        jsonschema.validate(instance=instance, schema=schema)\n",
        "\n",
        "        return True\n",
        "    except jsonschema.exceptions.ValidationError as err:\n",
        "        print(\"Invalid JSON format. Error:\", err)\n",
        "        return False\n",
        "\n",
        "def generate_json():\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    json_response = \"\"\n",
        "    for response in responses:\n",
        "        json_response += response.text.strip()\n",
        "\n",
        "    if json_response.startswith(\"```json\") and json_response.endswith(\"```\"):\n",
        "        json_response = json_response[7:-3].strip()\n",
        "\n",
        "    try:\n",
        "        json_object = json.loads(json_response)\n",
        "        if validate_json(json_object, schema):\n",
        "            return json_object\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error decoding JSON:\", e)\n",
        "    return None\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 2048,\n",
        "    \"temperature\": 0.4,\n",
        "    \"top_p\": 0.4,\n",
        "    \"top_k\": 32,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "generated_profile = generate_json()\n",
        "print(f\"{json.dumps(generated_profile, indent=2) if generated_profile else 'None'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48111e02-8877-4dee-a046-586ef9d3299f",
      "metadata": {
        "id": "48111e02-8877-4dee-a046-586ef9d3299f"
      },
      "source": [
        "# Guided Generation with Context-Free Grammars (CFGs)\n",
        "Defines a context-free grammar using the NLTK library to generate simple sentences. The grammar specifies the structure of a sentence (S), noun phrase (NP), and verb phrase (VP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89ef336-fe13-4fb1-ac1b-b61c8c4656e4",
      "metadata": {
        "tags": [],
        "id": "b89ef336-fe13-4fb1-ac1b-b61c8c4656e4",
        "outputId": "284c39b4-f690-4b56-b1e3-92b483b9fee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "John eats an apple\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from nltk import CFG\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> 'John' | 'Mary' | 'Alice' | 'Bob'\n",
        "    VP -> V Obj\n",
        "    V -> 'eats' | 'drinks' | 'sees' | 'likes'\n",
        "    Obj -> Det N\n",
        "    Det -> 'an' | 'a'\n",
        "    N -> 'apple' | 'banana' | 'water' | 'book'\n",
        "\"\"\")\n",
        "\n",
        "vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Generate a sentence based on the following context-free grammar:\n",
        "{grammar}\n",
        "Ensure there is a space between each word in the sentence.\n",
        "\"\"\"\n",
        "\n",
        "def generate_cfg_sentence():\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text.strip()\n",
        "\n",
        "    return response_text\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 100,\n",
        "    \"temperature\": 0.4,\n",
        "    \"top_p\": 0.9,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "\n",
        "generated_llm_sentence = generate_cfg_sentence()\n",
        "print(f\"{generated_llm_sentence}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ccd7bbe-36a6-4850-a508-e1a99eaf6f11",
      "metadata": {
        "id": "8ccd7bbe-36a6-4850-a508-e1a99eaf6f11"
      },
      "source": [
        "# Template-based Generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ff6d57-430a-4593-9057-488f3be6af03",
      "metadata": {
        "tags": [],
        "id": "02ff6d57-430a-4593-9057-488f3be6af03",
        "outputId": "b8103a78-36a8-42cc-c9bc-dc7611963849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name:John Smith\n",
            "Age: 35\n",
            "Email: john.smith@example.com\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
        "\n",
        "prompt = \"\"\"\n",
        "Create a user profile using the following template:\n",
        "Name: {{name}}\n",
        "Age: {{age}}\n",
        "Email: {{email}}\n",
        "\n",
        "Ensure the name is a first name and a last name, the age is a number between 20 and 40, and the email is in the format name@example.com.\n",
        "\"\"\"\n",
        "\n",
        "def generate_template_based_profile():\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text.strip()\n",
        "\n",
        "    return response_text\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 100,\n",
        "    \"temperature\": 0.4,\n",
        "    \"top_p\": 0.9,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "generated_profile = generate_template_based_profile()\n",
        "print(f\"{generated_profile}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab2c957-fa3e-4cd8-a9b1-d85b6fce3975",
      "metadata": {
        "id": "2ab2c957-fa3e-4cd8-a9b1-d85b6fce3975"
      },
      "source": [
        "# Entity-based Generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c79c0d-c029-4572-ae44-2ac4f9f8626f",
      "metadata": {
        "tags": [],
        "id": "02c79c0d-c029-4572-ae44-2ac4f9f8626f",
        "outputId": "9bdfaa80-d902-406e-962b-a07e39428883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nestled in the heart of Europe, France boasts the captivating capital of Paris, renowned for its iconic Eiffel Tower and the Louvre Museum. Indulge in the delectable aroma of freshly baked croissants, a culinary staple that embodies the nation's rich gastronomic heritage. The official language, French, echoes through the streets, adding a touch of elegance and sophistication to the vibrant atmosphere.\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
        "\n",
        "entities = {\n",
        "    \"country\": \"France\",\n",
        "    \"capital\": \"Paris\",\n",
        "    \"famous_food\": \"croissant\",\n",
        "    \"language\": \"French\"\n",
        "}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Generate a 3-line paragraph about {entities['country']} that includes the following entities:\n",
        "1. The capital city, {entities['capital']}\n",
        "2. A famous food, {entities['famous_food']}\n",
        "3. The official language, {entities['language']}\n",
        "\"\"\"\n",
        "\n",
        "def generate_entity_based_paragraph():\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text.strip() + \" \"\n",
        "\n",
        "    return response_text.strip()\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 200,\n",
        "    \"temperature\": 0.4,\n",
        "    \"top_p\": 0.9,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "generated_paragraph = generate_entity_based_paragraph()\n",
        "print(f\"{generated_paragraph}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c46cc5-2610-4a45-a64a-539f5c5a7494",
      "metadata": {
        "id": "c4c46cc5-2610-4a45-a64a-539f5c5a7494"
      },
      "source": [
        "# Structured Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b71ed6-ac70-49fa-b2f3-ea68c5fa857d",
      "metadata": {
        "tags": [],
        "id": "f9b71ed6-ac70-49fa-b2f3-ea68c5fa857d",
        "outputId": "0ace54ca-c191-486d-a8f5-8335dd82558e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Country</th>\n",
              "      <th>Profession</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John</td>\n",
              "      <td>30</td>\n",
              "      <td>USA</td>\n",
              "      <td>Software Engineer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mary</td>\n",
              "      <td>25</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Doctor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bob</td>\n",
              "      <td>40</td>\n",
              "      <td>UK</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alice</td>\n",
              "      <td>28</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Lawyer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tom</td>\n",
              "      <td>35</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Architect</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Name  Age    Country         Profession\n",
              "0   John   30        USA  Software Engineer\n",
              "1   Mary   25     Canada             Doctor\n",
              "2    Bob   40         UK            Teacher\n",
              "3  Alice   28  Australia             Lawyer\n",
              "4    Tom   35    Germany          Architect"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "vertexai.init(project=\"cart-ppt-llm\", location=\"us-central1\")\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
        "\n",
        "column_headers = [\"Name\", \"Age\", \"Country\", \"Profession\"]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Generate a table with the following columns: {', '.join(column_headers)}.\n",
        "Provide data for 5 rows.\n",
        "Ensure that the table is properly formatted as CSV without any line breaks within rows.\n",
        "\"\"\"\n",
        "\n",
        "def generate_dataframe():\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text.strip()\n",
        "\n",
        "    return response_text\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 300,\n",
        "    \"temperature\": 0.4,\n",
        "    \"top_p\": 0.9,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "generated_table = generate_dataframe()\n",
        "\n",
        "\n",
        "df = pd.read_csv(io.StringIO(generated_table))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae0faca-3856-40be-addd-2bf5a811f337",
      "metadata": {
        "id": "7ae0faca-3856-40be-addd-2bf5a811f337"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cu113.m120",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113:m120"
    },
    "kernelspec": {
      "display_name": "Python 3 (Local)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}